{"cells":[{"cell_type":"markdown","metadata":{},"source":["## GPU 스펙 확인"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-31T07:59:20.397084Z","iopub.status.busy":"2024-05-31T07:59:20.396482Z","iopub.status.idle":"2024-05-31T07:59:21.502452Z","shell.execute_reply":"2024-05-31T07:59:21.501332Z","shell.execute_reply.started":"2024-05-31T07:59:20.397051Z"},"trusted":true},"outputs":[],"source":["!nvidia-smi"]},{"cell_type":"markdown","metadata":{},"source":["## 캐글 데이터 경로 확인"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"markdown","metadata":{},"source":["## 폴더 경로 설정"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-31T07:59:37.360983Z","iopub.status.busy":"2024-05-31T07:59:37.360116Z","iopub.status.idle":"2024-05-31T07:59:37.365085Z","shell.execute_reply":"2024-05-31T07:59:37.364051Z","shell.execute_reply.started":"2024-05-31T07:59:37.360950Z"},"trusted":true},"outputs":[],"source":["workspace_path = '/kaggle/input/clouds-segmentation2024spring'  # 본인의 파일 경로 반영"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["!pip install segmentation_models_pytorch"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["!pip install albumentations==0.4.6\n","!pip install yacs"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-31T08:46:28.891683Z","iopub.status.busy":"2024-05-31T08:46:28.891044Z","iopub.status.idle":"2024-05-31T08:46:28.898427Z","shell.execute_reply":"2024-05-31T08:46:28.897363Z","shell.execute_reply.started":"2024-05-31T08:46:28.891651Z"},"trusted":true},"outputs":[],"source":["import os\n","import cv2\n","import numpy as np\n","from tqdm import tqdm\n","import warnings\n","import random\n","from torch.utils.data import DataLoader\n","from torch.utils.data import Dataset as BaseDataset\n","import torch\n","import segmentation_models_pytorch.utils as utils\n","import segmentation_models_pytorch as smp\n","from segmentation_models_pytorch.utils import base\n","from segmentation_models_pytorch.utils import functional as F\n","from segmentation_models_pytorch.base.modules import Activation\n","from segmentation_models_pytorch.utils.metrics import IoU\n","import albumentations as albu\n","import torch.nn as nn\n","from sklearn.model_selection import train_test_split\n","from PIL import Image\n","import torchvision.transforms as T"]},{"cell_type":"markdown","metadata":{},"source":["## patch"]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2024-05-31T09:32:41.736873Z","iopub.status.busy":"2024-05-31T09:32:41.736031Z","iopub.status.idle":"2024-05-31T09:32:41.750569Z","shell.execute_reply":"2024-05-31T09:32:41.749481Z","shell.execute_reply.started":"2024-05-31T09:32:41.736837Z"},"trusted":true},"outputs":[],"source":["def save_patches(image, mask, patch_size, stride, save_dir, base_name):\n","    img_height, img_width = image.shape[:2]\n","    patch_id = 0\n","\n","    for y in range(0, img_height - patch_size + 1, stride):\n","        for x in range(0, img_width - patch_size + 1, stride):\n","            img_patch = image[y:y + patch_size, x:x + patch_size]\n","            mask_patch = mask[y:y + patch_size, x:x + patch_size]\n","\n","            img_patch_path = os.path.join(save_dir, 'ngr', f\"{base_name}_{patch_id}.png\")\n","            mask_patch_path = os.path.join(save_dir, 'label', f\"{base_name}_{patch_id}.png\")\n","\n","            cv2.imwrite(img_patch_path, img_patch)\n","            cv2.imwrite(mask_patch_path, mask_patch)\n","\n","            patch_id += 1\n","\n","def patch(data_dir, patch_dir):\n","    patch_size = 224\n","    stride = 194\n","    save_dir = f'{patch_dir}/{patch_size}_{stride}'  # 패치가 저장될 디렉토리토리\n","\n","    if not os.path.exists(save_dir):\n","        os.makedirs(save_dir)\n","    if not os.path.exists(os.path.join(save_dir, 'label')):\n","        os.makedirs(os.path.join(save_dir, 'label'))\n","    if not os.path.exists(os.path.join(save_dir, 'ngr')):\n","        os.makedirs(os.path.join(save_dir, 'ngr'))\n","\n","    image_files = [f for f in os.listdir(os.path.join(data_dir, 'ngr')) if f.endswith('.png')]\n","    mask_files = [f for f in os.listdir(os.path.join(data_dir, 'label')) if f.endswith('.png')]\n","\n","    for img_file, mask_file in tqdm(zip(image_files, mask_files), total=len(image_files)):\n","        image = cv2.imread(os.path.join(data_dir, 'ngr', img_file))\n","        mask = cv2.imread(os.path.join(data_dir, 'label', mask_file))\n","\n","        base_name = os.path.splitext(img_file)[0]\n","        save_patches(image, mask, patch_size, stride, save_dir, base_name)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-31T08:22:05.276542Z","iopub.status.busy":"2024-05-31T08:22:05.275890Z","iopub.status.idle":"2024-05-31T08:23:53.474023Z","shell.execute_reply":"2024-05-31T08:23:53.473052Z","shell.execute_reply.started":"2024-05-31T08:22:05.276502Z"},"trusted":true},"outputs":[],"source":["data_dir = f'{workspace_path}/train'\n","\n","patch_dir = '/kaggle/working/cache'\n","os.makedirs(patch_dir, exist_ok=True)\n","\n","patch(data_dir, patch_dir)"]},{"cell_type":"markdown","metadata":{},"source":["## seg_train"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-31T09:01:13.090820Z","iopub.status.busy":"2024-05-31T09:01:13.090449Z","iopub.status.idle":"2024-05-31T09:15:22.364257Z","shell.execute_reply":"2024-05-31T09:15:22.363246Z","shell.execute_reply.started":"2024-05-31T09:01:13.090793Z"},"trusted":true},"outputs":[],"source":["warnings.filterwarnings(\"ignore\")\n","    \n","seed = 42\n","num_workers = 0\n","\n","patch_size = 224\n","patch_stride = 194\n","\n","data_dir = f'{patch_dir}/{patch_size}_{patch_stride}/ngr'\n","mask_dir = f'{patch_dir}/{patch_size}_{patch_stride}/label'\n","\n","batch_size = 32\n","epochs = 1\n","\n","learning_rate = 0.001\n","weight_decay = 0\n","\n","def set_seed(seed):\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    if torch.cuda.is_available():\n","        torch.cuda.manual_seed_all(seed)\n","        torch.backends.cudnn.benchmark = False\n","\n","set_seed(seed)\n","\n","class Dataset(BaseDataset):\n","\n","    def __init__(\n","            self, \n","            images_fps, \n","            masks_fps, \n","            augmentation=None, \n","            preprocessing=None,\n","            classes=None, \n","            palette=None,\n","            add_cloud_agumentation_TF=False,\n","    ):\n","        self.images_fps = images_fps\n","        self.masks_fps = masks_fps\n","\n","        self.CLASSES = classes\n","        self.class_values = [self.CLASSES.index(cls.lower()) for cls in classes]\n","        self.PALETTE = palette\n","\n","        for i in range(len(self.masks_fps)):\n","            self.mask_ids = np.unique(cv2.imread(self.masks_fps[i], 0))[1:]\n","            if len(self.mask_ids) == len(self.class_values):\n","                break\n","\n","        self.augmentation = augmentation\n","        self.preprocessing = preprocessing\n","        self.add_cloud_agumentation_TF = add_cloud_agumentation_TF\n","\n","    def __getitem__(self, i):\n","\n","        image = cv2.imread(self.images_fps[i])\n","        mask = cv2.imread(self.masks_fps[i])\n","\n","        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","        mask = cv2.cvtColor(mask, cv2.COLOR_BGR2RGB)\n","\n","        # PALETTE를 사용하여 마스크를 클래스 인덱스로 변환\n","        mask_class = np.zeros((mask.shape[0], mask.shape[1]), dtype=np.float32)\n","        for color, class_idx in self.PALETTE.items():\n","            mask_class[np.all(mask == color, axis=-1)] = class_idx\n","\n","        # 특정 클래스 마스크 추출\n","        masks = [(mask_class == v) for v in self.class_values]\n","        mask = np.stack(masks, axis=-1).astype('float')\n","\n","        if self.augmentation:\n","            sample = self.augmentation(image=image, mask=mask)\n","            image, mask = sample['image'], sample['mask']\n","\n","        if self.preprocessing:\n","            sample = self.preprocessing(image=image, mask=mask)\n","            image, mask = sample['image'], sample['mask']\n","\n","        return image, mask\n","\n","    def __len__(self):\n","        return len(self.images_fps)\n","\n","def to_tensor(x, **kwargs):\n","    return x.transpose(2, 0, 1).astype('float32')\n","\n","def get_preprocessing(preprocessing_fn):\n","\n","    _transform = [\n","        albu.Lambda(image=preprocessing_fn),\n","        albu.Lambda(image=to_tensor, mask=to_tensor),\n","    ]\n","    return albu.Compose(_transform)\n","\n","def get_training_augmentation():\n","    train_transform = [\n","        albu.HorizontalFlip(p=0.5),\n","        albu.VerticalFlip(p=0.5),\n","        albu.RandomRotate90(p=0.5),\n","    ]\n","\n","    return albu.Compose(train_transform)\n","\n","def get_validation_augmentation():\n","    test_transform = [\n","    ]\n","    return albu.Compose(test_transform)\n","\n","ENCODER = 'timm-efficientnet-b0'\n","ENCODER_WEIGHTS = 'imagenet' # 'imagenet', 'pre-trained from:..', None\n","CLASSES = ['background', 'thick_cloud', 'thin_cloud', 'cloud_shadow']\n","PALETTE = {\n","    (0, 0, 0): 0, # background\n","    (255, 0, 0): 1,  # thick_cloud\n","    (0, 255, 0): 2,  # thin_cloud\n","    (255, 255, 0): 3  # cloud_shadow\n","}\n","ACTIVATION = 'softmax'\n","DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","model = smp.FPN(\n","    encoder_name=ENCODER, \n","    encoder_weights=ENCODER_WEIGHTS, \n","    in_channels=3,\n","    classes=len(CLASSES), \n","    activation=ACTIVATION,\n",").to(DEVICE)\n","\n","preprocessing_fn = smp.encoders.get_preprocessing_fn(ENCODER, ENCODER_WEIGHTS)\n","\n","image_files = [os.path.join(data_dir, f) for f in os.listdir(data_dir) if f.endswith('.png')]\n","mask_files = [os.path.join(mask_dir, f) for f in os.listdir(mask_dir) if f.endswith('.png')]\n","\n","train_images, valid_images, train_masks, valid_masks = train_test_split(image_files, mask_files, test_size=0.2, random_state=42)\n","\n","train_dataset = Dataset(\n","    train_images, \n","    train_masks, \n","    augmentation=get_training_augmentation(), \n","    preprocessing=get_preprocessing(preprocessing_fn),\n","    classes=CLASSES,\n","    palette=PALETTE,\n",")\n","\n","valid_dataset = Dataset(\n","    valid_images, \n","    valid_masks, \n","    augmentation=get_validation_augmentation(), \n","    preprocessing=get_preprocessing(preprocessing_fn),\n","    classes=CLASSES,\n","    palette=PALETTE,\n",")\n","\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n","valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n","\n","class CombinedLoss(nn.Module):\n","    def __init__(self, loss_a, loss_b, weight_a=0.5, weight_b=0.5):\n","        super(CombinedLoss, self).__init__()\n","        self.loss_a = loss_a\n","        self.loss_b = loss_b\n","        self.weight_a = weight_a\n","        self.weight_b = weight_b\n","        self.__name__ = loss_a.__class__.__name__ + '_' + loss_b.__class__.__name__ \n","\n","    def forward(self, output, target):\n","        return self.weight_a * self.loss_a(output, target) + self.weight_b * self.loss_b(output, target)\n","\n","class DiceScore(base.Metric):\n","    __name__ = \"dice_score\"\n","\n","    def __init__(self, eps=1e-7, threshold=0.5, activation=None, ignore_channels=None, **kwargs):\n","        super().__init__(**kwargs)\n","        self.eps = eps\n","        self.threshold = threshold\n","        self.activation = Activation(activation)\n","        self.ignore_channels = ignore_channels\n","\n","    def forward(self, y_pr, y_gt):\n","        y_pr = self.activation(y_pr)\n","        return F.f_score(\n","            y_pr,\n","            y_gt,\n","            eps=self.eps,\n","            beta=1.0,  \n","            threshold=self.threshold,\n","            ignore_channels=self.ignore_channels,\n","        )\n","\n","DiceLoss = utils.losses.DiceLoss()\n","CE_Loss = torch.nn.CrossEntropyLoss()\n","combined_criterion = CombinedLoss(DiceLoss, CE_Loss, weight_a=0.5, weight_b=0.5)\n","\n","metrics = [\n","    DiceScore(),\n","    IoU(),\n","]\n","\n","optimizer = torch.optim.AdamW([\n","    dict(params=model.parameters(), lr=learning_rate, weight_decay=weight_decay),\n","])\n","\n","train_epoch = utils.train.TrainEpoch(\n","    model, \n","    loss=combined_criterion, \n","    metrics=metrics, \n","    optimizer=optimizer,\n","    device=DEVICE,\n","    verbose=True,\n",")\n","\n","valid_epoch = utils.train.ValidEpoch(\n","    model, \n","    loss=combined_criterion, \n","    metrics=metrics, \n","    device=DEVICE,\n","    verbose=True,\n",")\n","\n","# save_dir = os.path.join('./', 'ckpt')\n","save_dir = os.path.join('/kaggle/working/', 'ckpt')\n","os.makedirs(save_dir, exist_ok=True)\n","\n","dataset = f'aug_{patch_size}_{patch_stride}'\n","\n","max_dice_score = 0\n","\n","for epoch in range(epochs):\n","    print('\\nEpoch: {}'.format(epoch))\n","    \n","    train_logs = train_epoch.run(train_loader)\n","    valid_logs = valid_epoch.run(valid_loader)\n","    print('train dice score:', train_logs['dice_score'], 'train iou score:', train_logs['iou_score'])\n","    print('valid dice score:', valid_logs['dice_score'], 'valid iou score:', valid_logs['iou_score'])\n","\n","    if valid_logs['dice_score'] > max_dice_score:\n","        max_dice_score = valid_logs['dice_score']\n","        torch.save(model, os.path.join(save_dir, f'{dataset}_best_model.pth'))\n","\n","# ============================ Augmentation 없는 모델 훈련 (Ensamble) ===========================================        \n","\n","def get_training_augmentation():\n","    train_transform = []\n","\n","    return albu.Compose(train_transform)\n","\n","train_dataset = Dataset(\n","    train_images, \n","    train_masks, \n","    augmentation=get_training_augmentation(), \n","    preprocessing=get_preprocessing(preprocessing_fn),\n","    classes=CLASSES,\n","    palette=PALETTE,\n",")\n","\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n","\n","model = smp.FPN(\n","    encoder_name=ENCODER, \n","    encoder_weights=ENCODER_WEIGHTS, \n","    in_channels=3,\n","    classes=len(CLASSES), \n","    activation=ACTIVATION,\n",").to(DEVICE)\n","\n","optimizer = torch.optim.AdamW([\n","    dict(params=model.parameters(), lr=learning_rate, weight_decay=weight_decay),\n","])\n","\n","train_epoch = utils.train.TrainEpoch(\n","    model, \n","    loss=combined_criterion, \n","    metrics=metrics, \n","    optimizer=optimizer,\n","    device=DEVICE,\n","    verbose=True,\n",")\n","\n","valid_epoch = utils.train.ValidEpoch(\n","    model, \n","    loss=combined_criterion, \n","    metrics=metrics, \n","    device=DEVICE,\n","    verbose=True,\n",")\n","\n","dataset = f'non_aug_{patch_size}_{patch_stride}'\n","\n","max_dice_score = 0\n","\n","for epoch in range(epochs):\n","    print('\\nEpoch: {}'.format(epoch))\n","    \n","    train_logs = train_epoch.run(train_loader)\n","    valid_logs = valid_epoch.run(valid_loader)\n","    print('train dice score:', train_logs['dice_score'], 'train iou score:', train_logs['iou_score'])\n","    print('valid dice score:', valid_logs['dice_score'], 'valid iou score:', valid_logs['iou_score'])\n","\n","    if valid_logs['dice_score'] > max_dice_score:\n","        max_dice_score = valid_logs['dice_score']\n","        torch.save(model, os.path.join(save_dir, f'{dataset}_best_model.pth'))"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"databundleVersionId":8374131,"sourceId":77087,"sourceType":"competition"}],"dockerImageVersionId":30716,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
