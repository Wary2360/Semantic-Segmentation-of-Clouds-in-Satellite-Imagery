{"cells":[{"cell_type":"markdown","metadata":{},"source":["## GPU 스펙 확인"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-31T07:59:20.397084Z","iopub.status.busy":"2024-05-31T07:59:20.396482Z","iopub.status.idle":"2024-05-31T07:59:21.502452Z","shell.execute_reply":"2024-05-31T07:59:21.501332Z","shell.execute_reply.started":"2024-05-31T07:59:20.397051Z"},"trusted":true},"outputs":[],"source":["!nvidia-smi"]},{"cell_type":"markdown","metadata":{},"source":["## 캐글 데이터 경로 확인"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"markdown","metadata":{},"source":["## 폴더 경로 설정"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-31T07:59:37.360983Z","iopub.status.busy":"2024-05-31T07:59:37.360116Z","iopub.status.idle":"2024-05-31T07:59:37.365085Z","shell.execute_reply":"2024-05-31T07:59:37.364051Z","shell.execute_reply.started":"2024-05-31T07:59:37.360950Z"},"trusted":true},"outputs":[],"source":["workspace_path = '/kaggle/input/clouds-segmentation2024spring'  # 본인의 파일 경로 반영"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["!pip install segmentation_models_pytorch"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["!pip install albumentations==0.4.6\n","!pip install yacs"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-31T08:46:28.891683Z","iopub.status.busy":"2024-05-31T08:46:28.891044Z","iopub.status.idle":"2024-05-31T08:46:28.898427Z","shell.execute_reply":"2024-05-31T08:46:28.897363Z","shell.execute_reply.started":"2024-05-31T08:46:28.891651Z"},"trusted":true},"outputs":[],"source":["import os\n","import cv2\n","import numpy as np\n","from tqdm import tqdm\n","import warnings\n","import random\n","from torch.utils.data import DataLoader\n","from torch.utils.data import Dataset as BaseDataset\n","import torch\n","import segmentation_models_pytorch.utils as utils\n","import segmentation_models_pytorch as smp\n","from segmentation_models_pytorch.utils import base\n","from segmentation_models_pytorch.utils import functional as F\n","from segmentation_models_pytorch.base.modules import Activation\n","from segmentation_models_pytorch.utils.metrics import IoU\n","import albumentations as albu\n","import torch.nn as nn\n","from sklearn.model_selection import train_test_split\n","from PIL import Image\n","import torchvision.transforms as T"]},{"cell_type":"markdown","metadata":{},"source":["## patch"]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2024-05-31T09:32:41.736873Z","iopub.status.busy":"2024-05-31T09:32:41.736031Z","iopub.status.idle":"2024-05-31T09:32:41.750569Z","shell.execute_reply":"2024-05-31T09:32:41.749481Z","shell.execute_reply.started":"2024-05-31T09:32:41.736837Z"},"trusted":true},"outputs":[],"source":["def save_patches(image, mask, patch_size, stride, save_dir, base_name):\n","    img_height, img_width = image.shape[:2]\n","    patch_id = 0\n","\n","    for y in range(0, img_height - patch_size + 1, stride):\n","        for x in range(0, img_width - patch_size + 1, stride):\n","            img_patch = image[y:y + patch_size, x:x + patch_size]\n","            mask_patch = mask[y:y + patch_size, x:x + patch_size]\n","\n","            img_patch_path = os.path.join(save_dir, 'ngr', f\"{base_name}_{patch_id}.png\")\n","            mask_patch_path = os.path.join(save_dir, 'label', f\"{base_name}_{patch_id}.png\")\n","\n","            cv2.imwrite(img_patch_path, img_patch)\n","            cv2.imwrite(mask_patch_path, mask_patch)\n","\n","            patch_id += 1\n","\n","def patch(data_dir, patch_dir):\n","    patch_size = 224\n","    stride = 194\n","    save_dir = f'{patch_dir}/{patch_size}_{stride}'  # 패치가 저장될 디렉토리토리\n","\n","    if not os.path.exists(save_dir):\n","        os.makedirs(save_dir)\n","    if not os.path.exists(os.path.join(save_dir, 'label')):\n","        os.makedirs(os.path.join(save_dir, 'label'))\n","    if not os.path.exists(os.path.join(save_dir, 'ngr')):\n","        os.makedirs(os.path.join(save_dir, 'ngr'))\n","\n","    image_files = [f for f in os.listdir(os.path.join(data_dir, 'ngr')) if f.endswith('.png')]\n","    mask_files = [f for f in os.listdir(os.path.join(data_dir, 'label')) if f.endswith('.png')]\n","\n","    for img_file, mask_file in tqdm(zip(image_files, mask_files), total=len(image_files)):\n","        image = cv2.imread(os.path.join(data_dir, 'ngr', img_file))\n","        mask = cv2.imread(os.path.join(data_dir, 'label', mask_file))\n","\n","        base_name = os.path.splitext(img_file)[0]\n","        save_patches(image, mask, patch_size, stride, save_dir, base_name)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-31T08:22:05.276542Z","iopub.status.busy":"2024-05-31T08:22:05.275890Z","iopub.status.idle":"2024-05-31T08:23:53.474023Z","shell.execute_reply":"2024-05-31T08:23:53.473052Z","shell.execute_reply.started":"2024-05-31T08:22:05.276502Z"},"trusted":true},"outputs":[],"source":["data_dir = f'{workspace_path}/train'\n","\n","patch_dir = '/kaggle/working/cache'\n","os.makedirs(patch_dir, exist_ok=True)\n","\n","patch(data_dir, patch_dir)"]},{"cell_type":"markdown","metadata":{},"source":["## seg_test_ensamble"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-31T09:15:37.103610Z","iopub.status.busy":"2024-05-31T09:15:37.103262Z","iopub.status.idle":"2024-05-31T09:15:37.122115Z","shell.execute_reply":"2024-05-31T09:15:37.121060Z","shell.execute_reply.started":"2024-05-31T09:15:37.103583Z"},"trusted":true},"outputs":[],"source":["def load_model(model_path, device):\n","    model = torch.load(model_path)\n","    model = model.to(device)\n","    model.eval()\n","    return model\n","\n","def get_preprocessing(preprocessing_fn):\n","    _transform = [\n","        albu.Lambda(image=preprocessing_fn),\n","        albu.Lambda(image=lambda x, **kwargs: x.transpose(2, 0, 1).astype('float32')),\n","    ]\n","    return albu.Compose(_transform)\n","\n","def predict(model, image, preprocessing, device, patch_size=224, stride=97):\n","    height, width, _ = image.shape\n","    num_classes = 4  # 클래스 수\n","    output_mask = np.zeros((num_classes, height, width), dtype=np.float32)\n","    count_mask = np.zeros((height, width), dtype=np.float32)\n","\n","    with torch.no_grad():\n","        for y in range(0, height - patch_size + 1, stride):\n","            for x in range(0, width - patch_size + 1, stride):\n","                patch = image[y:y + patch_size, x:x + patch_size]\n","                sample = preprocessing(image=patch)['image']\n","                sample = torch.from_numpy(sample).to(device).unsqueeze(0)\n","                prediction = model(sample)\n","                prediction = prediction.squeeze().cpu().numpy()\n","                \n","                output_mask[:, y:y + patch_size, x:x + patch_size] += prediction\n","                count_mask[y:y + patch_size, x:x + patch_size] += 1\n","\n","        # Normalize the output mask by the count mask to get the average\n","        for c in range(num_classes):\n","            output_mask[c] /= count_mask\n","\n","    return output_mask\n","\n","def seg_test_ensamble(first_model_path, second_model_path, test_images_dir, device='cuda' if torch.cuda.is_available() else 'cpu'):\n","    encoder = 'efficientnet-b0'\n","    encoder_weights = 'imagenet'\n","    preprocessing_fn = smp.encoders.get_preprocessing_fn(encoder, encoder_weights)\n","    \n","    PALETTE = {\n","        (0, 0, 0): 0, # background\n","        (255, 0, 0): 1,  # thick_cloud\n","        (0, 255, 0): 2,  # thin_cloud\n","        (255, 255, 0): 3  # cloud_shadow\n","    }\n","    \n","    first_model = load_model(first_model_path, device)\n","    second_model = load_model(second_model_path, device)\n","    preprocessing = get_preprocessing(preprocessing_fn)\n","\n","    test_images = os.listdir(test_images_dir)\n","    for image_name in tqdm(test_images):\n","        image_path = os.path.join(test_images_dir, image_name)\n","        image = cv2.imread(image_path)\n","        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","        \n","        first_mask = predict(first_model, image, preprocessing, device)\n","        second_mask = predict(second_model, image, preprocessing, device)\n","        mask = (first_mask + second_mask) / 2\n","        \n","        mask = np.argmax(mask, axis=0)\n","        color_mask = np.zeros((mask.shape[0], mask.shape[1], 3), dtype=np.uint8)\n","        for color, class_idx in PALETTE.items():\n","            color_mask[mask == class_idx] = color\n","        mask = cv2.cvtColor(color_mask, cv2.COLOR_RGB2BGR)\n","        cv2.imwrite(f'/kaggle/working/predicted_masks/{image_name}', mask)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-31T09:15:43.241724Z","iopub.status.busy":"2024-05-31T09:15:43.241350Z","iopub.status.idle":"2024-05-31T09:25:29.044243Z","shell.execute_reply":"2024-05-31T09:25:29.043306Z","shell.execute_reply.started":"2024-05-31T09:15:43.241692Z"},"trusted":true},"outputs":[],"source":["first_model_path = '/kaggle/working/ckpt/aug_224_194_best_model.pth'\n","second_model_path = '/kaggle/working/ckpt/non_aug_224_194_best_model.pth'\n","test_images_dir = f'{workspace_path}/test/ngr'\n","os.makedirs('/kaggle/working/predicted_masks', exist_ok=True)\n","seg_test_ensamble(first_model_path, second_model_path, test_images_dir)"]},{"cell_type":"markdown","metadata":{},"source":["## result_to_csv"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-31T09:25:33.347463Z","iopub.status.busy":"2024-05-31T09:25:33.346706Z","iopub.status.idle":"2024-05-31T09:25:38.740774Z","shell.execute_reply":"2024-05-31T09:25:38.739756Z","shell.execute_reply.started":"2024-05-31T09:25:33.347424Z"},"trusted":true},"outputs":[],"source":["def mask2rle(img):\n","    '''\n","    img: numpy array, 1 - mask, 0 - background\n","    Returns run length as string formatted\n","    '''\n","    pixels= img.T.flatten()\n","    pixels = np.concatenate([[0], pixels, [0]])\n","    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n","    runs[1::2] -= runs[::2]\n","    return ' '.join(str(x) for x in runs)\n","\n","result_path = '/kaggle/working/predicted_masks'\n","\n","test_label_file_list = os.listdir(result_path)\n","test_label_path_list = [os.path.join(result_path, x) for x in test_label_file_list]\n","\n","rle_list = []\n","for file_path in test_label_path_list:\n","    img = cv2.imread(file_path)\n","    rle = mask2rle(img)\n","    rle_list.append(rle)\n","    \n","submission = pd.read_csv(f'{workspace_path}/sample_submission.csv')\n","\n","submission['Image_Label'] = test_label_file_list\n","submission['EncodedPixels'] = rle_list\n","\n","os.makedirs('/kaggle/working/csv', exist_ok=True)\n","submission.to_csv('/kaggle/working/csv/ensamble.csv', index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"databundleVersionId":8374131,"sourceId":77087,"sourceType":"competition"}],"dockerImageVersionId":30716,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
